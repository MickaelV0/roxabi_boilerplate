---
title: "Brainstorm: DGouron/review-flow Analysis"
description: Analysis of DGouron/review-flow for epic #163
type: brainstorm
---

## Context

**GitHub sub-issue:** [#164](https://github.com/roxabi/boilerplate/issues/164)
**Repository:** [DGouron/review-flow](https://github.com/DGouron/review-flow)
**Stars / Activity:** 25 stars, last commit 2026-02-17 (very active, 100+ PRs merged)

## Summary Table

| Axis | Rating | One-liner |
|------|--------|-----------|
| What it does | ðŸŸ¢ | Webhook-driven AI code review automation for GitLab/GitHub via Claude Code â€” entirely different domain |
| How it works | ðŸŸ¢ | Multi-agent pipeline with MCP integration, smart queue, and real-time WebSocket dashboard |
| Architecture | ðŸŸ¢ | Textbook Clean Architecture (entities â†’ use cases â†’ interface adapters â†’ frameworks) with published DDD ubiquitous language |
| File structure | ðŸŸ¡ | Single-app flat monolith; structured but no monorepo â€” different scale than roxabi |
| Tech stack | ðŸŸ¡ | Near-identical stack (TypeScript strict, Biome, Vitest, Fastify, Zod) minus Bun and TurboRepo |
| DX | ðŸŸ¡ | Good scripts and hot reload; CLI-first tooling; weaker env management (plain JSON config) |
| Testing | ðŸŸ¢ | Unit + integration + factory/stub layers with explicit test isolation â€” more disciplined than roxabi |
| CI/CD | ðŸ”´ | Minimal CI (lint + type + test + build on master only); no preview deploys, no staging gate |
| Documentation | ðŸŸ¢ | VitePress site with architecture docs, MCP spec, ubiquitous language reference, and LLM-optimized index |
| Unique ideas | ðŸŸ¢ | LLM-optimized doc index, Claude-as-skill invocation, MCP server for review progress, Cloudflare tunnel for local webhooks |

## Detailed Analysis

### 1. What It Does ðŸŸ¡

review-flow automates AI code reviews by hooking into GitLab/GitHub webhooks. When a developer assigns a reviewer on an MR/PR, the system spawns Claude Code with a configurable "skill" (a Markdown prompt file), posts inline comments, tracks progress in real time via WebSocket, and automatically follows up when the author pushes fixes.

- **Purpose:** Replace or augment human code reviewers with Claude Code, making AI review a first-class CI participant.
- **Target audience:** Individual developers and small teams wanting automated review quality gates without managing a cloud AI review service.
- **Problem solved:** Bridging the gap between Claude Code (a local CLI tool) and asynchronous, webhook-driven review workflows.

Rating is ðŸŸ¡ because this is a different domain from roxabi (SaaS framework vs. review automation tool). There is no direct competition or learning for what roxabi *does*, but there is rich learning in *how* it is built.

### 2. How It Works ðŸŸ¢

The runtime flow: GitLab/GitHub fires a webhook â†’ Cloudflare tunnel delivers it to the local Fastify server â†’ signature is verified â†’ event is filtered â†’ a `ReviewJob` is enqueued in `p-queue` (max 2 concurrent) â†’ Claude Code is spawned as a child process with a skill Markdown file â†’ progress is parsed from Claude's stdout via text markers â†’ actions (post comment, resolve thread, add label) are batched and executed via platform CLI (`glab`/`gh`) â†’ results are broadcast over WebSocket to the dashboard.

Follow-up reviews are triggered automatically when the author pushes after threads remain open: Claude re-reads threads and checks resolution rather than performing a full re-review.

The MCP layer is an additional integration path: a local MCP server exposes structured tools (`updateReviewProgress`, `markReviewComplete`, etc.) so Claude can emit typed progress events instead of relying on text-marker parsing.

Key design insight: Claude is never called as an API â€” it is always invoked as a CLI subprocess running a skill file. This means the system is fully local, uses existing Claude Code auth, and supports arbitrary prompt customization without any API key management.

### 3. Architecture & Layers ðŸŸ¢

review-flow follows **Uncle Bob's Clean Architecture** with four concentric layers, explicitly documented and enforced by directory structure:

```
entities/           # Domain objects (ReviewRequest, ReviewJob, Thread, ReviewActionâ€¦)
usecases/           # Application business logic (triggerReview, cancelReview, handlePushâ€¦)
interface-adapters/ # Controllers (webhook, MCP), gateways (filesystem), presenters
frameworks/         # Fastify, Claude CLI invoker, p-queue adapter, pino logger
```

The dependency rule is respected: inner layers never import from outer layers. Gateways are injected via interfaces (`ReviewRequestTrackingGateway`, `StatsGateway`, `ReviewFileGateway`) and composed in `main/dependencies.ts` â€” a manual DI container.

DDD vocabulary is formalized in a **Ubiquitous Language reference** (`docs/reference/ubiquitous-language.md`) with state machine diagrams and platform-to-domain term mapping (e.g., MergeRequest â†’ ReviewRequest, Discussion â†’ Thread).

Compared to roxabi (which uses NestJS DI, lacks explicit architectural boundaries documentation, and mixes domain logic into controllers), review-flow's architecture is more deliberately structured and better documented.

### 4. File / Project Structure ðŸŸ¡

Single-app flat repository (no monorepo). Layout mirrors Clean Architecture layers:

```
src/
â”œâ”€â”€ claude/               # Claude CLI invoker, progress parser
â”œâ”€â”€ cli/                  # CLI entry (init, start, validate commands)
â”œâ”€â”€ config/               # Config loader + validation (Zod)
â”œâ”€â”€ entities/             # Domain types and interfaces
â”œâ”€â”€ frameworks/           # External adapters (claude, queue, logging, settings)
â”œâ”€â”€ interface-adapters/   # Controllers, gateways, presenters, views
â”œâ”€â”€ main/                 # Composition root (dependencies.ts, routes.ts, server.ts)
â”œâ”€â”€ mcp/                  # MCP server infrastructure
â”œâ”€â”€ security/             # Webhook signature verification
â”œâ”€â”€ services/             # Application services (stats, thread actions, agent builder)
â”œâ”€â”€ shared/               # Cross-cutting utilities (path resolution, MCP context)
â”œâ”€â”€ tests/                # Mirrors src/ structure: units/, integration/, stubs/, factories/
â””â”€â”€ usecases/             # Business orchestration
docs/
â”œâ”€â”€ architecture/         # Current + target architecture, MCP spec
â”œâ”€â”€ guide/                # Getting started, skills, troubleshooting
â”œâ”€â”€ reference/            # Config schema, markers, MCP tools, ubiquitous language
â””â”€â”€ specs/                # SPEC documents for planned features
templates/
â”œâ”€â”€ skills/               # Default review skill prompts (Markdown)
â””â”€â”€ SKILL.md.template     # Skill authoring template
```

The `tests/` directory mirrors `src/` structure with separate `stubs/` and `factories/` subdirectories â€” a disciplined test layout that roxabi lacks. The `specs/` directory with formal SPEC documents is a strong parallel to roxabi's `specs/` workflow.

### 5. Tech Stack & Tooling ðŸŸ¡

| Tool | review-flow | roxabi_boilerplate |
|------|-------------|-------------------|
| Runtime | Node.js >=20 | Bun |
| Package manager | Yarn (lockfile) | Bun |
| Language | TypeScript 5.x strict | TypeScript 5.x strict |
| HTTP framework | Fastify 5 | Fastify (via NestJS) |
| Linter/Formatter | Biome (lint-only, no format) | Biome (lint + format) |
| Test runner | Vitest 4 | Vitest 4 |
| Schema validation | Zod 4 | Zod |
| Logging | Pino | NestJS logger (Pino-based) |
| Build | tsc + tsc-alias | Vite / NestJS CLI |
| Docs site | VitePress | â€” (MDX pages in TanStack) |
| Monorepo | None | TurboRepo |
| Git hooks | None | Lefthook |
| Release | release-please | Manual |

Notable: review-flow uses `yarn` + `package-lock.json` and `yarn.lock` simultaneously (likely a leftover). Biome is configured **lint-only** with formatting disabled â€” roxabi enables both. Both projects converge on strict TypeScript, Biome, Vitest 4, and Zod 4, confirming this as a strong modern TypeScript tooling baseline.

### 6. Developer Experience (DX) ðŸŸ¡

**Scripts:**
- `dev`: tsx watch for hot reload
- `build`: tsc + tsc-alias + asset copy
- `verify`: typecheck + lint + test:ci (equivalent to roxabi's pre-push hook)
- `docs:dev/build/preview`: VitePress

**CLI tooling:** review-flow ships as a global npm package (`npm install -g reviewflow`) with an interactive init wizard (`@inquirer/prompts`) â€” a very different DX model from roxabi's repo-local dev server.

**Config:** JSON file (`config.json`) + `.env` for secrets. Zod-validated at startup. No per-environment switching â€” single config for all environments.

**Onboarding:** `reviewflow init` wizard generates config interactively. README has a clear quick-start. Two-file setup (`.env` + `config.json`).

**Weaknesses vs roxabi:** No git hooks (no pre-commit lint), no commitlint, no env sync check, no worktree workflow. Config management is simpler but less powerful than roxabi's env-per-deployment model.

### 7. Testing Strategy ðŸŸ¢

review-flow has a well-structured testing approach:

- **Unit tests** (`tests/units/`): per-domain component, mirroring src structure
- **Integration tests** (`tests/integration/`): cross-component flows
- **Stubs** (`tests/stubs/`): reusable fake implementations of gateways
- **Factories** (`tests/factories/`): test data builders

Coverage configured with V8 provider, HTML + lcov + text reporters. `src/dashboard/` and test files explicitly excluded from coverage. `vitest:globals` enabled.

The `stubs/` + `factories/` separation is more mature than roxabi's current test setup. The test organization mirrors the source architecture, making it easy to find tests for a given layer.

**Weakness:** No e2e tests (no browser, no full-system smoke tests). Integration tests appear to cover the service layer but not the full HTTP + webhook stack.

### 8. CI/CD Pipelines ðŸ”´

Three workflows:

**ci.yml** â€” Runs on push/PR to `master`:
1. TypeScript check
2. Biome lint
3. Build
4. Vitest tests

No parallelization, no caching beyond yarn deps, no coverage reporting, no branch protection configuration visible.

**release.yml** â€” Runs on push to `master`:
- Uses `release-please` to auto-create release PRs from Conventional Commits
- On release creation: builds, tests, publishes to npm

**docs-deploy.yml** â€” Deploys VitePress docs to GitHub Pages.

Compared to roxabi: no preview deployments, no staging gate, no environment separation, no secrets management strategy, single branch model (`master`). The CI is minimal for a tool of this maturity. The release automation via `release-please` is a strength (automated CHANGELOG + semver from commits) that roxabi currently does manually.

### 9. Documentation Quality ðŸŸ¢

review-flow has the strongest documentation of any project in this comparison set:

- **VitePress site** (`docs/`) deployed to GitHub Pages at `dgouron.github.io/review-flow`
- **Architecture docs**: current state diagram (ASCII art data-flow), target Clean Architecture design, MCP spec
- **Ubiquitous Language reference**: domain terms, state machines, platform mapping table â€” DDD done right
- **LLM-optimized index** (`docs/llm-index.md`): a dedicated navigation file designed for LLM agents to quickly locate documentation â€” innovative and self-aware about AI tooling workflows
- **SPEC documents**: formal specs for planned features (e.g., SPEC-003 skill templates)
- **CONTRIBUTING.md**: clear dev workflow, commit message conventions, PR process
- **Markers reference**: text-marker syntax for AI progress tracking (custom protocol documentation)

The `llm-index.md` concept is particularly novel: it acknowledges that LLM agents consume documentation differently than humans, and provides a structured navigation file optimized for that use case.

**Weakness:** No API docs or generated TypeScript interface documentation. No changelog visible in the VitePress site (only CHANGELOG.md at root).

### 10. Unique / Novel Ideas ðŸŸ¢

**1. Claude-as-subprocess (skill invocation model)**
Rather than calling the Anthropic API, review-flow spawns the `claude` CLI as a child process and passes a Markdown "skill" file as the prompt. This means:
- Zero additional API key management (reuses existing Claude Code auth)
- Prompt customization is just editing a Markdown file â€” no code changes
- Multi-agent reviews are just multiple CLI invocations with different skill files
- The skill system is composable and user-configurable

**2. MCP server as progress API**
The MCP server exposes typed tools (`updateReviewProgress`, `markReviewComplete`, `addReviewThread`) so Claude can emit structured progress events. This is more reliable than text-marker parsing and enables two-way communication between the orchestrating process and the Claude subprocess.

**3. LLM-optimized documentation index**
`docs/llm-index.md` is explicitly designed for LLM agents, not human readers. It provides topic clusters and navigation hints that an LLM can use to quickly locate relevant context. This is a transferable pattern for any project that uses Claude Code or similar tools.

**4. Smart queue with deduplication**
`p-queue` with a configurable deduplication window (default 5 minutes) prevents double-reviews when multiple webhooks fire in rapid succession (e.g., force-push then assignment). Memory guard (4 GB limit) prevents runaway Claude processes from crashing the server.

**5. Automatic follow-up reviews**
Detecting `openThreads > 0` + `state === pending-fix` + a new push event triggers a targeted follow-up review using a different skill. The follow-up skill focuses only on whether previous issues were resolved, rather than full re-review. This models a real human review workflow.

**6. Ubiquitous Language as executable documentation**
The UL document defines not just terms but state machines (`ReviewJob` states, `ReviewRequest` states) and platform mapping tables. It functions as both documentation and a contract for domain code naming.

### 11. What They Do Better Than roxabi_boilerplate

**a. Clean Architecture enforcement**
review-flow's directory structure *is* the architecture. Every file has an obvious home. Dependency direction is explicit. roxabi uses NestJS modules but lacks explicit architectural boundary enforcement â€” services, entities, and controllers are mixed within feature modules without a formal layer contract.

Actionable: Define explicit architectural layers in roxabi's `apps/api` and document them. Consider a `docs/architecture/` section mirroring review-flow's current/target structure.

**b. Ubiquitous Language documentation**
review-flow maintains a formal UL reference with domain terms, state machines, and cross-platform term mapping. roxabi has no equivalent vocabulary document.

Actionable: Create `docs/architecture/ubiquitous-language.mdx` for roxabi's core domain (users, subscriptions, organizations, etc.).

**c. Test organization with stubs and factories**
The `tests/stubs/` + `tests/factories/` pattern makes test setup reusable and explicit. roxabi's tests are less organized about test data management.

Actionable: Introduce `tests/stubs/` and `tests/factories/` conventions in roxabi's API app.

**d. LLM-optimized doc index**
`llm-index.md` is a zero-cost improvement that makes Claude Code sessions more effective by giving the agent a pre-structured navigation file.

Actionable: Create `docs/llm-index.mdx` for roxabi with topic clusters and direct links â€” particularly useful given roxabi's CLAUDE.md-driven agent workflows.

**e. Release automation (release-please)**
Automated CHANGELOG generation and semver bumping from Conventional Commits via `release-please`. roxabi's `/promote` workflow is manual.

Actionable: Evaluate `release-please` as a replacement for roxabi's manual promote workflow.

**f. SPEC documents in version control**
`specs/` contains formal SPEC-NNN documents (e.g., SPEC-003). roxabi also has `specs/` but the SPEC numbering convention and formal structure are stronger in review-flow.

### 12. What They Do Better Than 2ndBrain

2ndBrain is a Python-based personal productivity system (knowledge base, Telegram bot, Google Workspace automation). The comparison is limited by domain difference.

**a. Formal architecture documentation**
review-flow documents its architecture explicitly (current + target states, data flow diagrams). 2ndBrain's architecture is described in `docs/architecture.md` but lacks the layer-by-layer rigor.

**b. TypeScript over Python for tooling clarity**
review-flow's type system enforces contracts at compile time. 2ndBrain's Python codebase relies on runtime checks and type hints without the same enforcement.

**c. CI/CD automation**
review-flow has automated release management via `release-please` and npm publish. 2ndBrain has no CI pipeline visible.

**d. Published package model**
review-flow ships as a globally installable npm package with a versioned CHANGELOG. 2ndBrain is an internal tool with no distribution model.

**e. MCP integration**
review-flow's MCP server is a native integration, giving Claude structured tool access. 2ndBrain does not use MCP.

The strengths are mostly in the same areas as the roxabi comparison: architecture discipline, release automation, and MCP-native design.

### 13. Key Takeaways

**Priority 1 â€” Must have:**

1. **LLM-optimized doc index** (`docs/llm-index.mdx`): Low effort, high impact for Claude Code sessions. Mirrors the existing `CLAUDE.md` reference table but structured as a VitePress page for agent navigation.

2. **Ubiquitous Language document** (`docs/architecture/ubiquitous-language.mdx`): Define roxabi's core domain vocabulary (User, Organization, Subscription, Plan, etc.) with state machines. Prevents naming drift across frontend/backend.

3. **Test stubs + factories convention**: Introduce `tests/stubs/` and `tests/factories/` directories in `apps/api` and `apps/web`. Reduces test setup boilerplate and makes test isolation explicit.

**Priority 2 â€” Worth evaluating:**

4. **`release-please` integration**: Replace the manual `/promote` workflow with automated CHANGELOG generation and GitHub Release creation from Conventional Commits. Pairs well with roxabi's existing commitlint setup.

5. **Architecture layer documentation**: Add `docs/architecture/layers.mdx` to roxabi documenting the explicit dependency rules between NestJS modules, domain entities, and infrastructure â€” analogous to review-flow's current/target architecture docs.

**Priority 3 â€” Nice to have:**

6. **Skill-file pattern for Claude Code automations**: Adopt review-flow's pattern of Markdown "skill files" for Claude Code sub-tasks. Instead of inline prompts in scripts, maintain versioned skill files in `.claude/skills/` â€” which roxabi already does, but could be more formalized with a skill template (`SKILL.md.template`).

**Potential GitHub issues to create:**
- `docs: create ubiquitous language reference for core domain`
- `docs: add llm-optimized navigation index`
- `test: introduce stubs and factories directories in apps/api`
- `chore: evaluate release-please for changelog automation`

## What's next?

review-flow is one of the most architecturally mature repos in this comparison set despite its young age (created 2026-01-30). The Clean Architecture implementation, ubiquitous language documentation, and MCP-native design are all worth bringing back to roxabi. The highest-leverage action is creating the LLM-optimized doc index â€” it takes under an hour and immediately improves every Claude Code session on the project.
