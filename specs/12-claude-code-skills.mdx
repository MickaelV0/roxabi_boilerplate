---
title: "Claude Code Skills"
description: Specification for 9 Claude Code skills covering the full dev lifecycle — from idea to merged PR.
status: implemented
---

## Context

Roxabi operates with Claude Code as a **parallelized development workforce** (808 sessions, 680h compute, 624 commits). Four skills exist today (`/issues`, `/issue-triage`, `/interview`, `/cleanup`), covering issue tracking, spec creation, and git housekeeping.

**What's missing:** Everything between "I have an issue" and "it's merged" — the actual dev workflow. Usage data (808 sessions) shows the highest friction in: wrong approach spirals (27 instances), CSS debugging failures (724min worst case), and repetitive scaffolding consuming multiple sessions.

**Reference:** [Usage Insights Analysis](../analyses/claude-code-usage-insights)

**Blocks:** Every future feature implementation benefits from these skills.

## Goal

Deliver 9 skills across 3 phases that cover the **full development lifecycle**:

```
Idea → Analysis → Spec → Plan → Scaffold → Code → Test → Review → Commit → PR
 ↑                         ↑      ↑                         ↑           ↑
 /interview              /plan  /scaffold                  /review     /commit
 /bootstrap ────────────┴──────┘                           /test       /pr
                                                                       /adr
```

## Human Gates

No skill takes an irreversible action without explicit user consent. The following approval gates are enforced across all skills:

| Gate | Skill(s) | What the user approves |
|------|----------|----------------------|
| Analysis approval | `/bootstrap`, `/interview` | Analysis content before proceeding to spec |
| Spec approval | `/bootstrap`, `/interview` | Spec content before proceeding to plan |
| Plan approval | `/bootstrap`, `/plan` | Implementation plan before scaffolding |
| Commit message | `/commit`, `/scaffold` | Message content before `git commit` |
| PR content | `/pr`, `/scaffold` | Title and body before `gh pr create` |
| Fix selection | `/review --fix` | Which findings to auto-fix (multi-select) |
| Review fixes | `/review --fix` | Applied diffs before any manual commit |
| Test content | `/test` | Generated tests before writing files |

**Rule: No skill auto-commits or auto-merges.**

## Skills Overview

| # | Skill | Phase | Type | Priority | Effort |
|---|-------|-------|------|----------|--------|
| 1 | `/interview` (improve) | 1 — Foundation | Pure SKILL.md | P1 | S |
| 2 | `/commit` | 1 — Foundation | Pure SKILL.md | P1 | S |
| 3 | `/pr` | 1 — Foundation | Pure SKILL.md | P1 | S |
| 4 | `/review` | 2 — Quality | Pure SKILL.md | P1 | L |
| 5 | `/test` | 2 — Quality | Pure SKILL.md | P2 | M |
| 6 | `/bootstrap` | 3 — Orchestration | Pure SKILL.md | P1 | M |
| 7 | `/scaffold` | 3 — Orchestration | Pure SKILL.md | P1 | M |
| 8 | `/adr` | 3 — Orchestration | Pure SKILL.md | P3 | S |
| 9 | `/plan` | 3 — Orchestration | Pure SKILL.md | P1 | S |

## Skill Interaction Matrix

| Skill | Hard Dependencies | Soft Suggestions |
|-------|------------------|-----------------|
| `/bootstrap` | `/interview`, `/plan` | — |
| `/scaffold` | `/commit`, `/pr` | — |
| `/review --fix` | — | `/commit` |

5 of 9 skills (`/interview`, `/commit`, `/pr`, `/test`, `/adr`) are fully standalone with no dependencies.

## Phasing

### Phase 1 — Foundation

Build the base skills that every other skill and workflow depends on.

| Skill | Depends on |
|-------|------------|
| `/interview` (improve) | — |
| `/commit` | — |
| `/pr` | `/commit` (same conventions) |

### Phase 2 — Quality

Build the quality assurance skills.

| Skill | Depends on |
|-------|------------|
| `/review` | `/commit` (fix agents use commit conventions) |
| `/test` | — |

### Phase 3 — Orchestration

Build the high-level orchestration skills that compose the others.

| Skill | Depends on |
|-------|------------|
| `/bootstrap` | `/interview` (analysis/spec), `/plan` (implementation plan) |
| `/scaffold` | `/commit`, `/pr` (calls them for commit + draft PR) |
| `/plan` | — |
| `/adr` | — |

---

## Skill 1: `/interview` (Improve Existing)

> **Replaces:** Ad-hoc conversations with no structure; tribal knowledge about what analyses/specs should contain.

### Current State

- Functional but **stateless and unguided**
- Two output types: Spec and Analysis
- No brainstorm template
- No interview methodology (just "ask probing questions")
- No flow between document types (can't promote analysis → spec)
- No awareness of existing docs for the topic

### Changes

#### 1.1 Add Brainstorm Output Type

New document type alongside Spec and Analysis:

| Type | Output | Purpose |
|------|--------|---------|
| **Brainstorm** | `analyses/{slug}.mdx` (with `type: brainstorm` in frontmatter) | Explore ideas, divergent thinking, no structure imposed |
| **Analysis** | `analyses/{slug}.mdx` | Structured investigation of a topic |
| **Spec** | `specs/{slug}.mdx` | Technical specification for implementation |

Brainstorm template:

```markdown
---
title: "Brainstorm: {Title}"
description: ...
---

## Trigger
{What started this exploration}

## Ideas
- **{Idea 1}**: {Description}
  - Upside: ...
  - Downside: ...

- **{Idea 2}**: {Description}
  - Upside: ...
  - Downside: ...

## What's next?
{Free text — promote to analysis, park it, or discard}
```

#### 1.2 Add Interview Guidance Framework

Replace the vague "ask probing questions" with structured methodology:

**Phase 1 — Context** (1-2 questions):
- What triggered this? What's the problem or opportunity?
- What exists today? What's been tried?

**Phase 2 — Scope** (2-3 questions):
- Who are the users? What are their workflows?
- What's explicitly out of scope?
- What are the constraints (technical, time, dependencies)?

**Phase 3 — Depth** (2-4 questions, topic-dependent):
- What are the edge cases and failure modes?
- What are the trade-offs? What are you willing to sacrifice?
- How does this integrate with existing systems?
- What does success look like? How do you measure it?

**Phase 4 — Validation** (1 question):
- Present a summary of understanding, ask for corrections before generating

The skill should **skip questions with obvious answers** from context (e.g., don't ask "what's the tech stack?" when CLAUDE.md already defines it).

#### 1.3 Add Document Flow

Allow promoting between types:

```
/interview --promote analyses/12-skills.mdx
```

Behavior:
1. Read the existing document
2. Determine current type (brainstorm or analysis)
3. Ask targeted questions to fill gaps for the next level
4. Generate the promoted document (analysis → spec)
5. Link the new document back to its source

#### 1.4 Add Existing Doc Awareness

Before starting an interview, check:
- `analyses/` for existing analyses matching the topic
- `specs/` for existing specs
- Related GitHub issues

If found, present them and ask: "An analysis already exists for this topic. Do you want to build on it, start fresh, or promote it to a spec?"

### Allowed Tools

`AskUserQuestion`, `Write`, `Read`, `Glob`

### Acceptance Criteria

- [ ] Three document types available: Brainstorm, Analysis, Spec
- [ ] Interview follows the 4-phase guidance framework
- [ ] `--promote` flag works to promote analysis → spec
- [ ] Existing docs are detected and surfaced before starting
- [ ] Templates for all three types are included in SKILL.md

---

## Skill 2: `/commit`

### Purpose

Enforce commit conventions and guard against common mistakes. Automates the mechanical parts of committing while keeping the user in control.

> **Replaces:** Manually crafting commit messages, forgetting Co-Authored-By trailers, occasionally committing debug code.

### Behavior

```
/commit                    → Interactive commit of staged changes
/commit --all              → Stage all modified tracked files, then commit
/commit -m "message"       → Commit with provided message (still validates)
```

### Process

1. **Gather state:**
   - `git status` — show staged/unstaged changes
   - `git diff --cached --stat` — summarize what will be committed
   - If nothing staged and no `--all` flag: warn and ask what to stage

2. **Guard rails:**
   - **Scope check:** If staged changes span >3 files and not in a worktree, warn: "You're modifying {N} files on {branch}. Consider using a worktree (Tier M+)."
   - **Debug check:** Scan staged files for `console.log`, `debugger`, `.only` in tests. Warn if found.
   - **Staged file check:** Block if `.env`, `credentials.json`, or similar secret files are staged. (In-code secret detection and lint are handled by Claude Code hooks — `/commit` does not duplicate those.)

3. **Generate commit message:**
   - Analyze the diff to determine type (`feat`, `fix`, `refactor`, etc.)
   - Detect scope from file paths (e.g., `apps/web/` → `web`, `apps/api/` → `api`)
   - Detect linked issue from branch name (e.g., `feat/42-auth` → `#42`)
   - Generate a conventional commit message
   - Present to user for approval via `AskUserQuestion`

4. **Commit:**
   - Run `git add` for specified files (never `git add -A`)
   - Run `git commit` with approved message + `Co-Authored-By` trailer
   - If pre-commit hook fails: catch the error, offer to fix, and create a NEW commit (never amend)
   - Show result

### Edge Cases

- **Pre-commit hook failure:** Fix the issue, re-stage, create NEW commit (never amend)
- **Empty diff:** Do nothing, inform user
- **Merge conflict markers:** Detect and block commit

### Allowed Tools

`Bash`, `AskUserQuestion`, `Read`, `Grep`

### Acceptance Criteria

- [ ] Conventional commit format enforced (type, scope, description)
- [ ] Scope auto-detected from file paths
- [ ] Issue number auto-detected from branch name
- [ ] Guard rails: >3 files warning, debug code detection, staged secret file detection
- [ ] Pre-commit hook failures handled gracefully (fix + new commit)
- [ ] User approves message before commit
- [ ] Co-Authored-By trailer always included

---

## Skill 3: `/pr`

### Purpose

Create pull requests with consistent format, proper linking, and guard rails. Natural pair with `/commit`.

> **Replaces:** Manually writing PR descriptions, forgetting to link issues, inconsistent PR formats across the team.

### Behavior

```
/pr                        → Create PR for current branch
/pr --draft                → Create draft PR
/pr --base develop         → Target a specific base branch
```

### Process

1. **Gather state:**
   - `git log main..HEAD` — all commits on branch
   - `git diff main...HEAD --stat` — all changed files
   - `gh pr list --head $(git branch --show-current)` — check if PR already exists
   - If PR exists: offer to update description instead of creating new

2. **Guard rails:**
   - **Branch check:** Refuse to create PR from `main`/`master`
   - **Push check:** If branch not pushed, push with `-u` flag first
   - **Up-to-date check:** Warn if branch is behind `main` (suggest rebase)
   - **Quality gates:** Run `bun lint && bun typecheck`. Warn (don't block) if failing.

3. **Generate PR content:**
   - Analyze all commits (not just latest) to understand the full change
   - Detect issue number from branch name → `Closes #XX`
   - Generate title in conventional commit format
   - Generate body with: Summary (1-3 bullets), Test plan, linked issue
   - Present to user for approval via `AskUserQuestion`

4. **Create PR:**
   - `gh pr create` with approved title and body
   - If `--draft` flag: add `--draft`
   - Display PR URL

### PR Body Template

```markdown
## Summary
- {bullet 1}
- {bullet 2}

## Test Plan
- [ ] {test item}

Closes #{issue_number}
```

### Allowed Tools

`Bash`, `AskUserQuestion`, `Read`, `Grep`

### Acceptance Criteria

- [ ] PR title follows conventional commit format
- [ ] Issue auto-linked from branch name
- [ ] All commits analyzed (not just latest)
- [ ] Quality gates run and reported (warnings, not blockers)
- [ ] PR body includes Summary + Test Plan
- [ ] Existing PR detected and update offered
- [ ] `--draft` and `--base` flags supported

---

## Skill 4: `/review`

### Purpose

Code review with optional automated fix pipeline. Default mode: review only (findings report). With `--fix`: review + parallel fix agents that apply changes without committing.

> **Replaces:** Manual code review with no checklist, inconsistent feedback format, no automated fix pipeline.

### Behavior

```
/review                    → Review current branch changes vs main
/review --fix              → Review + apply fixes (no auto-commit)
/review #42                → Review a specific PR by number
/review --fix #42          → Review + fix a specific PR
```

### Process — Review Mode (default)

1. **Gather changes:**
   - `git diff main...HEAD` — all changes on branch
   - Or `gh pr diff 42` — if reviewing a specific PR
   - Read all changed files in full (not just diff) for context

2. **Analyze with structured review:**
   - Read `docs/standards/code-review.mdx` for review checklist
   - Read relevant standards (`frontend-patterns.mdx`, `backend-patterns.mdx`, `testing.mdx`)
   - Categorize findings:

   | Category | Severity | Examples |
   |----------|----------|---------|
   | **Bug** | Blocker | Logic errors, null pointer, race conditions |
   | **Security** | Blocker | XSS, injection, exposed secrets |
   | **Standard violation** | Warning | Missing types, wrong naming, no tests |
   | **Style** | Suggestion | Readability, simplification, naming |
   | **Architecture** | Discussion | Design patterns, abstraction level |

3. **Present findings:**
   - Use Conventional Comments format
   - Group by category and severity
   - Include file path + line number for each finding
   - Summary: X blockers, Y warnings, Z suggestions

### Process — Fix Mode (`--fix`)

After the review step above:

4. **User selects findings to fix:**
   - Present all findings grouped by file via `AskUserQuestion` (multi-select)
   - User selects which findings to fix
   - Only selected findings proceed to fix agents

5. **Spawn fix agents:**
   - **Maximum 5 concurrent agents**
   - **Parallel across different files**, sequential within the same file
   - Each agent receives: the finding, the file content, the project standards
   - Each agent applies its fix
   - Each agent runs `bunx biome check --write` + `bun typecheck` on changed files
   - **Revert strategy:** Read file content into memory before applying fix. If typecheck or tests break after fix, restore the original content and mark as "could not auto-fix"

6. **Present fix report:**
   - Show all applied fixes as a unified diff
   - Show any findings that could not be auto-fixed (with reason)
   - **Never auto-commit.** User reviews the diff and decides what to keep.
   - Suggest running `/commit` to commit the approved changes.

### Edge Cases

- **No changes:** Inform user, nothing to review
- **Binary files:** Skip, note in report
- **Large PR (>50 files):** Warn about review quality, suggest splitting

### Allowed Tools

`Bash`, `AskUserQuestion`, `Read`, `Grep`, `Edit`, `Task` (for parallel fix agents)

### Acceptance Criteria

- [ ] Review follows `code-review.mdx` checklist
- [ ] Findings use Conventional Comments format
- [ ] Findings categorized by severity (Blocker, Warning, Suggestion)
- [ ] `--fix` presents findings for user selection via `AskUserQuestion` (multi-select)
- [ ] `--fix` spawns fix agents (max 5 concurrent, parallel across files, sequential within same file)
- [ ] Fix agents use file content snapshot for revert on typecheck/test failure
- [ ] Fixes never auto-committed — presented as diff for user approval
- [ ] PR number support (`/review #42`)

---

## Skill 5: `/test`

### Purpose

Generate tests for changed or specified files. Follows existing test patterns in the codebase.

> **Replaces:** Writing test files from scratch each time, inconsistent test patterns, no auto-detection of what needs tests.

### Behavior

```
/test                      → Generate tests for files changed vs main
/test src/auth/login.ts    → Generate tests for a specific file
/test --e2e                → Generate Playwright e2e tests for changed files
/test --run                → Run existing tests (shortcut for bun test)
```

### Process

1. **Identify targets:**
   - Default: `git diff main...HEAD --name-only` — files changed on branch
   - Filter to testable files (`.ts`, `.tsx`, exclude config, types-only files)
   - If specific file provided, use that

2. **Find existing patterns:**
   - Glob for existing test files near targets (`*.test.ts`, `*.spec.ts`)
   - Read 1-2 existing tests to understand patterns (describe/it structure, mocking approach, assertion style)
   - Check if the project uses `bun:test`, `vitest`, or another framework

3. **Generate tests:**
   - For each target file:
     - Read the file to understand exports and behavior
     - Generate unit tests covering: happy path, edge cases, error cases
     - Follow existing naming and structure patterns
     - Place test file adjacent to source (`login.ts` → `login.test.ts`)
   - Present generated tests for approval via `AskUserQuestion`

4. **Run and verify:**
   - Write approved test files
   - Run `bun test {test_file}` for each
   - Report results (pass/fail)
   - If failures: offer to fix

### E2E Mode (`--e2e`)

When `--e2e` flag is used:
- Check if Playwright is installed. If not, inform the user with the install command and stop. Skills do not install dependencies.
- Generate Playwright tests in `apps/web/e2e/`
- Follow Playwright patterns: `page.goto()`, `expect(page).toHaveURL()`, etc.

### Edge Cases

- **File with no exports:** Skip, suggest it may not need tests
- **Already has tests:** Offer to add missing coverage rather than overwrite
- **Test framework not detected:** Ask user which framework to use

### Allowed Tools

`Bash`, `AskUserQuestion`, `Read`, `Write`, `Glob`, `Grep`

### Acceptance Criteria

- [ ] Auto-detects changed files from branch diff
- [ ] Finds and follows existing test patterns
- [ ] Generates happy path + edge case + error tests
- [ ] Tests placed adjacent to source files
- [ ] `--e2e` checks for Playwright and informs user if missing
- [ ] `--e2e` generates Playwright tests in `apps/web/e2e/`
- [ ] Generated tests are run and verified
- [ ] User approves tests before writing

---

## Skill 6: `/bootstrap`

### Purpose

Planning orchestrator from idea to approved implementation plan. Multiple entry points depending on what already exists. Calls `/interview` for analysis/spec steps and `/plan` for implementation planning. Three validation gates. Stops at the approved plan — execution is handled by `/scaffold`.

> **Replaces:** Jumping straight to code without analysis/spec, or manual doc creation with ad-hoc structure.

### Behavior

```
/bootstrap "avatar upload"          → Start from scratch (idea)
/bootstrap --issue 42               → Start from existing issue
/bootstrap --spec 42                → Start from existing spec (skip to plan)
```

### Process

```
┌──────────────────────────────────────────────────────────────┐
│ GATE 1: Analysis                                             │
│                                                              │
│ Entry: /bootstrap "idea" or /bootstrap --issue 42            │
│                                                              │
│ 1. Check for existing docs:                                  │
│    - analyses/{issue-slug}.mdx                               │
│    - specs/{issue-slug}.mdx                                  │
│    - GitHub issue body                                       │
│                                                              │
│ 2. If no analysis exists:                                    │
│    - Call /interview in Analysis mode                        │
│    - Produces analyses/{slug}.mdx                            │
│                                                              │
│ 3. Present analysis → User approves ✓                        │
├──────────────────────────────────────────────────────────────┤
│ GATE 2: Spec                                                 │
│                                                              │
│ Entry: /bootstrap --spec 42                                  │
│                                                              │
│ 4. If no spec exists:                                        │
│    - Call /interview in Spec mode (--promote from analysis)  │
│    - Produces specs/{slug}.mdx                               │
│                                                              │
│ 5. Present spec → User approves ✓                            │
├──────────────────────────────────────────────────────────────┤
│ GATE 3: Implementation Plan                                  │
│                                                              │
│ 6. Call /plan to generate implementation plan:               │
│    (see Skill 9: /plan for full details)                     │
│                                                              │
│ 7. Present plan → User approves ✓                            │
│                                                              │
│ Output: Approved plan ready for /scaffold                    │
└──────────────────────────────────────────────────────────────┘
```

### Entry Point Logic

| Flag | Starts at | Skips |
|------|-----------|-------|
| `"idea text"` | Gate 1 (Analysis) | Nothing |
| `--issue 42` | Gate 1 (Analysis) | Reads issue body as starting context |
| `--spec 42` | Gate 2 (Spec) | Analysis (assumes spec exists in `specs/42-*.mdx`) |

### Edge Cases

- **Issue already has a spec:** Skip to Gate 2, present existing spec for validation
- **User rejects at any gate:** Stop and let user provide feedback, re-enter at same gate

### Allowed Tools

`Bash`, `AskUserQuestion`, `Read`, `Write`, `Glob`, `Grep`, `Task` (for calling `/interview`)

### Acceptance Criteria

- [ ] Three entry points working: bare idea, `--issue`, `--spec`
- [ ] Calls `/interview` for analysis and spec generation
- [ ] Three validation gates with user approval at each
- [ ] Existing docs detected and reused (no duplicate analysis/spec)
- [ ] Tier auto-suggested with user confirmation
- [ ] Stops at approved plan (does not scaffold or commit)

---

## Skill 7: `/scaffold`

### Purpose

Execution skill that takes an approved spec/plan and does the mechanical work: creates the GitHub issue, sets up the worktree, scaffolds boilerplate, commits, and opens a draft PR.

> **Replaces:** Manually creating worktrees, boilerplate files, GitHub issues, and draft PRs for each new feature.

### Behavior

```
/scaffold --spec 42                → Scaffold from existing spec
/scaffold --plan                   → Resume from in-progress plan (e.g., after /bootstrap)
```

### Process

1. **Create GitHub issue** (if none exists):
   - `gh issue create` with spec summary + acceptance criteria

2. **Create branch + worktree** (if tier M/L):
   - `git worktree add ../roxabi-XXX -b feat/XXX-slug`
   - If tier S: direct branch, no worktree

3. **Scaffold boilerplate:**
   - Find most similar feature as reference
   - Create file stubs following existing patterns
   - Types → API routes → UI components → test files

4. **Verify:**
   - `bun lint && bun typecheck`
   - If typecheck fails: report errors, let user decide whether to proceed

5. **Commit + draft PR:**
   - Call `/commit` conventions (user approves message)
   - Call `/pr --draft` (user approves PR content)
   - Display PR URL

### Rollback

If the scaffold is wrong, cleanup is two commands:

```bash
git worktree remove ../roxabi-XXX
gh pr close <PR_NUMBER>
```

### Edge Cases

- **Tier S detected:** Skip worktree creation, use direct branch
- **Scaffolding fails typecheck:** Report errors, let user decide whether to proceed
- **No spec found:** Inform user, suggest running `/bootstrap` first

### Allowed Tools

`Bash`, `AskUserQuestion`, `Read`, `Write`, `Glob`, `Grep`, `Edit`, `Task`

### Acceptance Criteria

- [ ] `--spec` and `--plan` entry points working
- [ ] GitHub issue created with spec summary
- [ ] Worktree created for tier M/L, direct branch for tier S
- [ ] Boilerplate follows existing codebase patterns
- [ ] Typecheck passes after scaffolding (or errors reported)
- [ ] Commit follows `/commit` conventions
- [ ] Draft PR created with proper linking
- [ ] Rollback path documented

---

## Skill 8: `/adr`

### Purpose

Create Architecture Decision Records to document **why** technical choices were made.

> **Replaces:** Architectural decisions made in conversations and never documented; rationale lost over time.

### Behavior

```
/adr "Fastify over Express"           → Create new ADR
/adr --list                            → List existing ADRs
```

### Process

1. **Determine next ADR number:**
   - Scan `docs/architecture/adr/` for existing ADRs (create directory on first run if it doesn't exist)
   - Increment the highest number

2. **Interview (brief):**
   - Ask via `AskUserQuestion`: Context, options considered, decision rationale, consequences
   - Keep it short — 2-3 questions max

3. **Generate ADR:**
   - Write to `docs/architecture/adr/{NNN}-{slug}.mdx`
   - Update `docs/architecture/adr/meta.json`

### ADR Template

```markdown
---
title: "ADR-{NNN}: {Title}"
description: {One-line summary of the decision}
---

# ADR-{NNN}: {Title}

## Status

{Proposed | Accepted | Deprecated | Superseded by ADR-XXX}

## Context

{What is the issue? Why does this decision need to be made?}

## Options Considered

### Option A: {Name}
- **Pros:** {advantages}
- **Cons:** {disadvantages}

### Option B: {Name}
- **Pros:** {advantages}
- **Cons:** {disadvantages}

## Decision

{What was decided and why.}

## Consequences

### Positive
- {benefit}

### Negative
- {trade-off}

### Neutral
- {side effect}
```

### Allowed Tools

`AskUserQuestion`, `Write`, `Read`, `Glob`

### Acceptance Criteria

- [ ] Auto-increments ADR number
- [ ] Creates `docs/architecture/adr/` on first run if it doesn't exist
- [ ] Brief interview (2-3 questions) captures context + decision + consequences
- [ ] ADR written to `docs/architecture/adr/`
- [ ] `meta.json` updated
- [ ] `--list` shows existing ADRs

---

## Skill 9: `/plan`

### Purpose

Generate a structured implementation plan from an existing spec. Extracted from `/bootstrap` Gate 3 to be usable independently.

> **Replaces:** Ad-hoc implementation planning with no structured breakdown of spec into tasks.

### Behavior

```
/plan --spec 42               → Generate plan from spec specs/42-*.mdx
/plan --spec path/to/spec.mdx → Generate plan from a specific spec file
```

### Process

1. **Read the spec:**
   - Locate spec by issue number (`specs/{N}-*.mdx`) or by path
   - If not found: inform user, suggest running `/bootstrap` or `/interview` first

2. **Analyze scope:**
   - Identify files to create/modify
   - Detect dependencies between tasks
   - Auto-suggest tier (S/M/L) based on file count and architectural impact

3. **Generate implementation plan:**
   - Break spec into ordered tasks
   - For each task: files affected, description, estimated effort
   - Define implementation order respecting dependencies
   - Present tier suggestion — user confirms or overrides via `AskUserQuestion`

4. **Present plan:**
   - Show full plan for approval via `AskUserQuestion`
   - If rejected: ask for feedback, regenerate
   - Output: approved plan ready for `/scaffold`

### Edge Cases

- **Spec not found:** Inform user, suggest `/bootstrap` or `/interview`
- **Spec too vague:** Ask clarifying questions before generating plan
- **User overrides tier:** Accept and adjust plan accordingly (e.g., skip worktree recommendation for S)

### Allowed Tools

`AskUserQuestion`, `Read`, `Glob`, `Grep`

### Acceptance Criteria

- [ ] Reads spec by issue number or file path
- [ ] Identifies files to create/modify
- [ ] Auto-suggests tier (S/M/L) with user confirmation
- [ ] Generates ordered task list with effort estimates
- [ ] Plan presented for user approval before proceeding
- [ ] Works standalone and when called from `/bootstrap`

---

## Non-Goals

- **Agent definitions** — Deferred. No `.claude/agents/` directory. Skills spawn Task subagents as needed.
- **`/save` skill** — Out of scope (belongs to 2ndBrain project).
- **`/spec` skill** — Redundant, covered by `/interview`.
- **`/playground` skill** — Removed from scope. No clear use case.
- **Marketplace audit** — Deferred to a separate investigation.

## Technical Decisions

All skills are pure SKILL.md files. Scripts (like `fetch_issues.sh`) are reserved for deterministic data fetching where a bash script is more reliable than Claude reasoning.

### Skill Structure

Each skill lives in `.claude/skills/{name}/SKILL.md` following the existing pattern:

```yaml
---
argument-hint: [flags and args]
description: One-line description for skill listing.
allowed-tools: Tool1, Tool2, ...
---
```

### CLAUDE.md Updates

After implementation, update the Available Skills table in `CLAUDE.md` with all new skills and their triggers.

## Constraints

- **No breaking changes** to existing skills (`/issues`, `/issue-triage`, `/interview`, `/cleanup`)
- **Skill independence:** Each skill must work standalone (except `/bootstrap` which calls `/interview` + `/plan`, and `/scaffold` which invokes `/commit` + `/pr`)
- **No new dependencies:** Skills use only Claude Code built-in tools + `gh` CLI + `git` + `bun`
- **Convention alignment:** All skills enforce conventions from `docs/contributing.mdx` and `docs/standards/`

## Success Criteria

- [ ] All 9 skills implemented and documented
- [ ] Phase 1 skills (`/interview`, `/commit`, `/pr`) working independently
- [ ] Phase 2 skills (`/review`, `/test`) working with `--fix` and `--e2e` flags
- [ ] Phase 3 skills (`/bootstrap`, `/scaffold`, `/plan`, `/adr`) working with all entry points
- [ ] `/bootstrap` successfully calls `/interview` for analysis/spec steps and `/plan` for implementation planning
- [ ] `/plan` generates implementation plans from specs with tier suggestion
- [ ] `/bootstrap` stops at approved plan (does not scaffold)
- [ ] `/scaffold` creates worktree, scaffolds, commits, and opens draft PR
- [ ] `/review --fix` presents findings for user selection, then spawns fix agents (max 5, parallel across files, sequential within) without auto-committing
- [ ] CLAUDE.md updated with all new skills
- [ ] Existing skills unmodified

## Resolved Decisions

1. **`/review --fix` agent isolation:** Fix agents run in parallel across different files (max 5 concurrent), sequentially within the same file. User selects which findings to fix via `AskUserQuestion` before agents spawn. Revert strategy: file content snapshot (read before fix, restore on failure).
2. **`/bootstrap` tier detection:** Auto-suggest a tier based on spec scope. User confirms or overrides via `AskUserQuestion`.
3. **`/test --e2e` and Playwright:** `/test --e2e` checks if Playwright is installed. If missing, informs the user with the install command and stops. Skills do not install dependencies.
4. **ADR directory:** `/adr` creates `docs/architecture/adr/` on first run if it doesn't exist.
5. **`/plan` extraction:** Implementation planning extracted from `/bootstrap` into standalone `/plan` skill for independent use. `/bootstrap` calls `/plan` for Gate 3.
