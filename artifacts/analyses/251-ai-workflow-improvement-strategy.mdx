---
title: "AI Workflow Improvement Strategy"
description: Strategy and execution plan for making the AI workflow smarter across the Roxabi boilerplate — prioritizing and sequencing 8 child issues under #251.
---

**Status:** Draft — Feb 2026
**Role:** This analysis feeds a spec. It defines strategy and phasing; the spec will detail implementation.

## Context

The Roxabi boilerplate has grown to 9 specialized agents, 15 skills, and a multi-stage pipeline (bootstrap → scaffold → review → promote). While functional, four pain points have emerged:

1. **Token waste** — Opus runs where Sonnet would suffice; sessions consume more than expected
2. **Agent coordination** — Subagents work in isolation; no shared task lists, duplicate effort possible
3. **Planning pipeline** — Large issues aren't broken down before scaffold; bootstrap produces one monolithic spec
4. **Skill architecture** — 15 flat SKILL.md files; agents struggle to discover and navigate related skills at scale

Issue #251 tracks 8 child issues addressing these problems. This analysis defines the strategy, prioritization, dependencies, and execution plan for all 8.

**Current state (Feb 2026):**
- 9 agents: `architect`, `backend-dev`, `devops`, `doc-writer`, `fixer`, `frontend-dev`, `product-lead`, `security-auditor`, `tester`
- 15 skills: `adr`, `agent-browser`, `bootstrap`, `cleanup`, `commit`, `interview`, `issue-triage`, `issues`, `1b1`, `pr`, `promote`, `retro`, `review`, `scaffold`, `test`
- Coordination: `TeamCreate` + `SendMessage` for multi-domain scaffold; no `CLAUDE_CODE_TASK_LIST_ID` shared state
- Pipeline: bootstrap (analysis → spec) → scaffold (plan → implement → PR) → review → promote

## Questions Explored

1. How should the 8 child issues be grouped and sequenced?
2. What are the dependencies between issues?
3. Which issues deliver the highest ROI earliest?
4. How do the three research issues (#252, #265, #266) feed into the implementation issues?
5. What is a realistic execution timeline?

## Analysis

### Issue Inventory

| # | Title | Type | Theme | Tier |
|---|-------|------|-------|------|
| 255 | Investigate high token consumption | Investigation | Token optimization | S |
| 254 | Set Sonnet by default for sub-agents | Optimization | Token optimization | S |
| 252 | Investigate TaskMaster.dev task splitting | Research | Planning pipeline | S |
| 265 | Evaluate obra/superpowers | Research | Skill/workflow architecture | S |
| 266 | Evaluate rjs/shaping-skills | Research | Planning pipeline | S |
| 263 | Setup shared task lists for subagents | Feature | Agent coordination | F-lite → F-full (see note) |
| 264 | Skill Graphs vs flat skills | Architecture | Skill architecture | F-lite |
| 253 | Smart issue splitting in bootstrap | Feature | Planning pipeline | F-full |

> **Note on #263:** Initially estimated F-lite, but shared task lists are a protocol-level change to agent coordination that affects the scaffold skill, all domain agents, and AGENTS.md. Architect involvement is required for design. Recommend treating as **F-full** to ensure proper spec and review.

### Dependency Graph

```
Phase 1 (Foundation)          Phase 2 (Research + Architecture)       Phase 2.5       Phase 3 (Pipeline)
─────────────────────         ──────────────────────────────────      ──────────      ──────────────────

#255 token investigation ──┐
                           ├──► #254 Sonnet defaults
                           │
                           │    #252 TaskMaster.dev ──────┐
                           │    #265 obra/superpowers ────┤
                           │    #266 rjs/shaping-skills ──┼──► Synthesis ──► #253 smart splitting
                           │                              │      gate
                           │    #263 shared task lists ───┘
                           │    #264 skill graphs (→ ADR)
                           │
                           └──► (all Phase 2 informed by token findings)
```

**Key dependencies:**
- **#255 → #254**: Token investigation findings determine which agents to downgrade to Sonnet and by how much
- **#252 + #265 + #266 → Synthesis → #253**: Research findings are consolidated in a synthesis document before #253 spec begins
- **#263 → #253**: Shared task lists enable coordinated execution of split sub-issues (enables operation, not design)
- **#264** is independent — can run in parallel with everything in Phase 2. However, if its findings recommend skill restructuring, this should be known before #253 is designed (skill integration concerns)

### Phase 1: Foundation (Do First)

**Goal:** Understand current costs and apply quick optimizations.

#### #255 — Investigate High Token Consumption (S-tier)

- Gather token usage data from Claude billing dashboard (per-organization usage)
- Analyze Claude Code session logs for per-agent/per-skill token patterns (session output length as proxy where granular data is unavailable)
- Look for patterns: context bloat, redundant reads, over-prompting, unnecessary tool calls
- **Output:** Analysis document at `artifacts/analyses/255-token-consumption.mdx` with top 5 consumption hotspots and recommended fixes
- **Fallback:** If billing data lacks per-session granularity, use session-level estimation (count tool calls × average tokens per tool type)

#### #254 — Set Sonnet by Default for Sub-agents (S-tier)

- Depends on #255 findings for data-driven decisions
- Candidate agents for Sonnet: `fixer`, `doc-writer`, `tester`, `devops` (routine tasks)
- Keep Opus for: `architect`, `product-lead`, `security-auditor` (judgment-heavy)
- Add `model: sonnet` to agent frontmatter where appropriate
- **Rollback mechanism:** Document the original model setting for each agent in a table within the PR description. If quality degrades, revert the frontmatter change. Monitor via manual review of next 3-5 agent sessions per changed agent.
- **Validation:** A/B test on 2-3 real tasks (same task run with Sonnet vs Opus) before merging
- **Output:** PR with updated agent definitions + before/after cost estimate
- **Fallback:** If #255 takes longer than expected, apply a conservative default list (fixer, doc-writer) without waiting for full investigation data, then refine after #255 completes

**Why first:** These are quick wins (S-tier, &lt;3 files each). Token savings compound — every subsequent issue benefits from lower per-session costs.

### Phase 2: Research + Architecture (Parallel)

**Goal:** Gather intelligence on external tools/methodologies and build structural improvements.

All three research issues run in parallel as independent investigations. Architecture issues proceed in parallel since they don't depend on research.

#### #252 — Investigate TaskMaster.dev (S-tier research)

- Evaluate task splitting capabilities and heuristics
- Assess: Can it be integrated as an MCP server or CLI tool?
- Focus on: How does it decompose tasks? What metadata does it produce?
- **Extract for #253:** Task splitting heuristics, dependency detection patterns, estimation signals
- **Output:** Analysis document at `artifacts/analyses/252-taskmaster-evaluation.mdx`

#### #265 — Evaluate obra/superpowers (S-tier research)

- Evaluate the agentic skills framework and software development methodology
- Compare skill organization patterns with our flat SKILL.md approach
- Assess: Does it solve the skill discovery problem (#264)?
- **Extract for #253/#264:** Skill composition patterns, methodology insights, agent autonomy techniques
- **Output:** Analysis document at `artifacts/analyses/265-superpowers-evaluation.mdx`

#### #266 — Evaluate rjs/shaping-skills (S-tier research)

- Evaluate Shape Up methodology adapted for Claude Code
- Assess: How does breadboarding/fat-marker sketching work in an AI context?
- Focus on: Pre-implementation shaping as an alternative to our bootstrap pipeline
- **Extract for #253:** Shaping heuristics, pitch format, appetite-based scoping
- **Output:** Analysis document at `artifacts/analyses/266-shaping-skills-evaluation.mdx`

#### #263 — Setup Shared Task Lists (F-full)

- Implement `CLAUDE_CODE_TASK_LIST_ID` for subagent coordination
- Enable parallel workers to read/write the same task list
- Integrate with scaffold's `TeamCreate` workflow
- **Scope impact:** This is a protocol-level change affecting the scaffold skill, every spawned agent, and AGENTS.md. Requires architect review during spec phase.
- **Current gap:** `TeamCreate` + `SendMessage` allows agents to communicate but not share a persistent task view. Agents cannot see what others are working on, leading to duplicate effort and lost coordination when sessions restart.
- **Prerequisite for #253:** Split sub-issues need coordinated execution via shared task lists
- **Output:** Spec at `artifacts/specs/263-shared-task-lists.mdx` → PR with implementation

#### #264 — Skill Graphs vs Flat Skills (F-lite)

- Evaluate interconnected `.md` network vs current flat SKILL.md files
- Prototype: Can skills reference each other? Does this improve agent discovery?
- Consider: Cross-skill navigation, dependency awareness, progressive disclosure
- **Timing concern:** If #264 recommends skill restructuring, it affects every skill file. Run in Phase 2 so findings are available before #253 is designed — otherwise #253 may need retroactive changes.
- **Output:** ADR at `docs/architecture/adr-XXX-skill-graphs.mdx` with recommendation (adopt, reject, or defer)

### Phase 2.5: Research Synthesis (Between Phase 2 and Phase 3)

**Goal:** Consolidate research findings into a single reference document before #253 spec begins.

After #252, #265, and #266 complete, produce a **synthesis document** that:
- Summarizes key findings from each research issue
- Identifies common patterns and contradictions between the three approaches
- Recommends which ideas to integrate into the #253 design
- Notes what to discard and why

**Output:** `artifacts/analyses/251-research-synthesis.mdx`

This step prevents the #253 spec author from having to reconcile three separate research documents independently and ensures conflicting conclusions are resolved explicitly.

### Phase 3: Pipeline Integration (After Synthesis)

**Goal:** Integrate research findings into a smarter bootstrap pipeline.

#### #253 — Smart Issue Splitting in Bootstrap (F-full)

This is the most complex issue and the culmination of the research phase. It requires its own full bootstrap pass (analysis → spec → scaffold).

It should incorporate:

- **From #252 (TaskMaster):** Task decomposition heuristics and patterns
- **From #265 (superpowers):** Skill composition and agent autonomy techniques
- **From #266 (shaping-skills):** Appetite-based scoping and shaping methodology
- **From #263 (shared task lists):** Coordination mechanism for split sub-issues
- **From #264 (skill graphs):** Skill integration model (if applicable)

**Design decisions to resolve in spec:**
- **Insertion point:** New gate inside the bootstrap skill (after spec approval, before handoff to scaffold) vs. standalone skill invoked between bootstrap and scaffold. Recommend: new bootstrap gate — keeps the pipeline linear and avoids a separate invocation step.
- **Interaction model:** Propose splits via `AskUserQuestion`, don't auto-create. User approves/adjusts before sub-issues are created.
- **Output format:** GitHub sub-issues with parent link, size/priority labels, dependency annotations
- **Execution:** Split issues feed into scaffold as independent worktrees with shared task lists (#263)
- **Architect involvement:** Required for spec review — this inserts a new stage into the bootstrap-to-scaffold handoff.

### Execution Timeline

| Week | Issues | Activities | Deliverables |
|------|--------|------------|-------------|
| **Week 1** | #255, #254 | Token investigation → Sonnet defaults. Quick wins. | 2 PRs (or 1 merged + 1 conservative default) |
| **Week 2** | #252, #265, #266, #264 | All 4 research/architecture issues in parallel. | 3 analysis docs + 1 ADR |
| **Week 3** | #263, synthesis | Shared task lists spec + implementation. Research synthesis. | 1 PR + 1 synthesis doc |
| **Week 4** | #253 (spec) | Bootstrap #253 — analysis + spec + approval gates. | 1 approved spec |
| **Week 5** | #253 (implement) | Scaffold #253 — plan, implement, PR. | 1 PR |

**Parallel execution note:** Week 2 runs 4 issues simultaneously. Each is an S-tier research or F-lite architecture issue, producing analysis documents — not code. This is manageable for a solo reviewer since research outputs are documents, not PRs requiring code review.

**Timeline risk:** If #255 takes longer than expected (billing data access, session reconstruction), #254 slides into Week 2, compressing the Phase 2 start. Mitigation: apply conservative Sonnet defaults for `fixer` and `doc-writer` without waiting for full data.

### Risk Assessment

| Risk | Mitigation |
|------|-----------|
| Research issues (#252, #265, #266) produce nothing actionable | Time-box each to 1 session. Even negative findings ("not suitable") inform #253 design. |
| Research issues reach conflicting conclusions | Phase 2.5 synthesis gate explicitly reconciles findings before #253 spec begins. |
| Shared task lists (#263) prove more complex than expected | Upgraded to F-full. Start with a minimal POC (single scaffold session with shared list) before full integration. |
| Smart splitting (#253) scope creep | Strictly scope to bootstrap pipeline. Don't try to change scaffold or review. |
| Token savings from #254 break agent quality | A/B test before switching + documented rollback procedure (revert frontmatter). Monitor next 3-5 sessions per changed agent. |
| #264 recommends skill restructuring that affects #253 | Run #264 in Phase 2 so findings are available. If restructuring is recommended, scope it as a separate follow-up issue — don't block #253. |

### Success Criteria

| Metric | Target | Measured by |
|--------|--------|-------------|
| Feature delivery speed | Bootstrap-to-PR pipeline completes in fewer sessions per feature | Compare session count for next 3 features vs. last 3 |
| Agent autonomy | Agents need fewer human corrections during scaffold | Track lead interventions per scaffold session |
| Skill discovery | Agents invoke the correct skill on first attempt | Monitor skill invocation accuracy in next 10 sessions |
| Token efficiency | Measurable reduction in per-session token consumption | Compare Claude billing data Week 5 vs. Week 0 baseline |

## Conclusions

1. **Phase the work in 4 stages**: Foundation → Research + Architecture (parallel) → Synthesis → Pipeline integration
2. **#255 and #254 are the obvious first movers** — low effort, immediate token savings, data-driven decisions for everything else
3. **Research issues (#252, #265, #266) should run in parallel** — independent investigations with no cross-dependencies
4. **A synthesis gate (Phase 2.5) is essential** — reconciles potentially conflicting research findings before #253 spec
5. **#253 is the crown jewel** — highest-impact issue but depends on 5 prior issues; needs its own full bootstrap pass (spec in Week 4, implementation in Week 5)
6. **#263 should be upgraded to F-full** — protocol-level change to agent coordination requires architect review
7. **#264 (skill graphs) is architecturally independent** — can run anytime in Phase 2, delivers an ADR with a clear adopt/reject/defer recommendation

## Next Steps

- [ ] Begin Phase 1: `/bootstrap --issue 255` for token investigation
- [ ] Apply #255 findings to #254 (Sonnet defaults) — or apply conservative defaults if #255 is delayed
- [ ] Phase 2: Run #252, #265, #266, #264 in parallel (4 sessions producing analysis docs + 1 ADR)
- [ ] Phase 2: `/bootstrap --issue 263` for shared task lists (F-full, architect involved)
- [ ] Phase 2.5: Write research synthesis document consolidating #252, #265, #266 findings
- [ ] Phase 3: `/bootstrap --issue 253` for smart issue splitting (F-full, separate bootstrap pass)
- [ ] Phase 3: `/scaffold --spec 253` to implement smart splitting
