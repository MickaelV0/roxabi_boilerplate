---
title: 'Phase 1: Practical Standards — Technical Analysis'
description: Deep codebase analysis of TanStack Query, Testing, and SOLID gaps for documentation
---

## Source

Epic #316 (child of #256 architecture standards audit). Three sub-issues: #260 TanStack Query, #261 Testing, #258 SOLID. Codebase audit identified these as highest-gap areas. Frame approved 2026-02-26.

## Problem

The codebase has mature foundations but three areas lack authoritative documentation. AI agents, onboarding developers, and code reviewers have no reference patterns for:

1. **TanStack Query** — No `queryOptions()`, no route prefetching, hardcoded keys, no documented cache strategy
2. **Testing** — No MSW, undocumented testing pyramid, no TanStack Query testing patterns
3. **SOLID** — Strong implicit compliance but zero explicit documentation for agents to follow

## Outcome

AI agents producing new queries, tests, and modules follow consistent, documented patterns. Code reviewers can cite specific standard sections when rejecting non-compliant code. The gap between implicit and explicit knowledge is closed for these three areas:

- **TanStack Query:** Agents know the canonical query factory pattern, key convention, prefetch approach, and cache strategy
- **Testing:** Agents know when to use unit vs integration vs E2E, how to mock HTTP calls, and how to test query hooks
- **SOLID:** Agents produce code that follows named SOLID principles as practiced in the codebase

## Appetite

1-week cycle. Docs only — no code changes, no config, no CI.

## Codebase Findings

### Area 1: TanStack Query (#260)

**Current state** (14 files use `useQuery`, 17 total using TanStack Query hooks, 0 use `useSuspenseQuery`):

| Pattern | Status | Evidence |
|---------|--------|----------|
| `queryOptions()` factories | Not used | All options inlined in `useQuery()` calls |
| Query keys | Mixed | Mostly hardcoded arrays; 2 files use `as const` constants (`FEATURE_FLAGS_QUERY_KEY`, `ORGANIZATIONS_QUERY_KEY`) |
| Route prefetching | Not used | `beforeLoad` is used in 33 files for auth guards, but none use it for data prefetching. `setupRouterSsrQueryIntegration()` exists in `router.tsx` — infrastructure is ready but unused for prefetch |
| `useSuspenseQuery` | Not used | All files use `useQuery` with explicit `isLoading`/`error` checks |
| State separation | Good | Server state via Query, client state via `useState`/context. Minimal duplication |
| Cache invalidation | Broad | `invalidateQueries()` in mutation `onSuccess` callbacks. No `setQueryData()` (no optimistic updates) |
| Custom hooks | Partial | `useCursorPagination` (infinite query wrapper), `useOrganizations`, `useEnrichedSession`. Most queries inline in routes |
| Mutations | Good pattern | `useMutation` + `onSuccess`/`onError` + `toast`. Cache invalidation via parent callbacks |
| QueryClient config | No global defaults | No global `staleTime`, retry, or error handling. 3 individual queries set per-query `staleTime` (30s-60s) |

**Key files:** `apps/web/src/lib/useOrganizations.ts`, `apps/web/src/hooks/useCursorPagination.ts`, `apps/web/src/routes/admin/members.tsx`, `apps/web/src/router.tsx`, `apps/web/src/lib/routePermissions.ts`

**Gap severity:** Large. Every new query added by agents will follow the inline pattern unless docs prescribe `queryOptions()` + key factories.

### Area 2: Testing (#261)

**Current state** (~194 test files, 93%+ coverage thresholds):

| Pattern | Status | Evidence |
|---------|--------|----------|
| Testing pyramid | Partially documented | `testing.mdx` documents the Testing Trophy model, but rationale for layer distribution and when-to-use guidance is missing. Heavy unit (75%+), limited integration (5 files), minimal E2E (3 Playwright specs) |
| MSW | Not used | Zero MSW references. All HTTP mocking via `vi.spyOn(globalThis, 'fetch')` |
| BDD style | Strong | "should..." convention consistently followed. Arrange-Act-Assert pattern |
| Test factories | Good frontend | `createMockSession()`, `createMockUser()` in `apps/web/src/test/__mocks__/`. Backend uses inline `createMockDb()` |
| Drizzle mocking | Custom | `createChainMock()` utility mimics Drizzle's fluent API for query builder mocking |
| Coverage config | Strict | V8 provider, 84-93% thresholds (lines: 93, functions: 92, branches: 84, statements: 92) |
| Vitest config | Layered | Base → React/Node presets (`packages/vitest-config/`) → app-level overrides |
| E2E | Playwright + POM | `AuthPage` page object, conditional CI skip, real API required |
| Integration | NestJS TestingModule | Real DI container, 5 spec files for auth/rbac/user/tenant/throttler |

**Key files:** `vitest.config.ts`, `packages/vitest-config/`, `apps/web/src/test/setup.ts`, `apps/api/src/admin/__test-utils__/createChainMock.ts`

**Gap severity:** Medium. BDD and factory patterns exist but are undocumented. MSW adoption is the largest single gap. Note: `testing.mdx` already covers mocking strategies, factory helpers, and coverage guidelines — the new content must complement (not duplicate) existing sections.

### Area 3: SOLID (#258)

**Backend (NestJS) — strong implicit compliance:**

| Principle | Status | Evidence |
|-----------|--------|---------|
| **SRP** | Strong | Services are domain-focused (AuthService: 79 lines, PermissionService: 63 lines). Minor gap: `UserService.softDelete()` mixes user deletion + org ownership resolution |
| **OCP** | Good | Exception filters extensible via `@Catch()` decorators. Guards use Reflector for decorator-based extension. Gap: `AllExceptionsFilter` has instanceof checks requiring modification for new types |
| **LSP** | Strong | Minimal inheritance. Domain exceptions extend Error correctly. Services use composition via DI |
| **ISP** | Strong | Lean DI tokens (`DRIZZLE`, `EMAIL_PROVIDER`). Focused method signatures. No bloated interfaces |
| **DIP** | Good | Token-based injection (`@Inject(DRIZZLE)`, `@Inject(EMAIL_PROVIDER)`). Module-level composition. Gap: services use raw Drizzle queries directly (no repository abstraction), coupling business logic to the ORM |

**Frontend (React) — good implicit compliance:**

| Principle | Status | Evidence |
|-----------|--------|---------|
| **SRP** | Good | Route = orchestrator, sub-components = presentational. Custom hooks extract state logic. Gap: some orchestration hooks return 10+ properties |
| **OCP** | Good | Components extensible via callback props. Dialog composition pattern. Gap: inline form validation, direct `fetch()` in routes |
| **LSP** | N/A | No class inheritance in React. Component contracts via TypeScript props |
| **ISP** | Strong | Lean prop interfaces (QuickActionCardProps: 6 props). Focused hook return types |
| **DIP** | Good | Hooks + context as abstraction layer. Gap: some routes call `fetch()` directly instead of through hooks |

**Key files:** `apps/api/src/common/filters/allExceptions.filter.ts`, `apps/api/src/auth/auth.guard.ts`, `apps/api/src/auth/auth.module.ts`, `apps/web/src/routes/settings/profile.tsx`

**Gap severity:** Small. Patterns are strong but implicit — documenting them makes agent output consistent.

### Existing Documentation State

| Doc | Lines | Already covers | Missing for #316 |
|-----|-------|----------------|-------------------|
| `frontend-patterns.mdx` | ~354 | Component strategy, TypeScript, error boundaries, shadcn/ui, file naming | TanStack Query patterns, state management, SOLID |
| `backend-patterns.mdx` | ~354 | Module structure, DI, exception handling, correlation ID, guards | SOLID principles, Drizzle patterns |
| `testing.mdx` | ~333 | Testing Trophy, TDD, AAA, coverage, Playwright, mocking strategies | MSW, testing pyramid rationale, TanStack Query testing |

All three docs share consistent style: hierarchical numbering, rules + anti-patterns, code examples, AI Quick Reference sections, MDX format.

## Shapes

### Shape 1: Extend Existing Docs (Recommended)

Add new sections to the three existing standards docs:

- `frontend-patterns.mdx` += TanStack Query section (queryOptions, keys, prefetch, cache) + SOLID frontend section
- `backend-patterns.mdx` += SOLID backend section (codify existing patterns with explicit principle labels)
- `testing.mdx` += MSW adoption plan section + testing pyramid rationale + TanStack Query testing patterns

Each section follows existing doc conventions: numbered headings, code examples, rules, AI Quick Reference additions.

**Trade-offs:**
- Pro: Consistent with existing structure. Single source of truth per domain. AI agents already read these files.
- Pro: No new files to maintain. Smaller review surface.
- Con: Docs grow longer (~500-600 lines each). Risk of monolithic reference docs.

**Rough scope:** M (3 doc extensions, each with 100-200 lines of new content + code examples)

### Shape 2: Standalone Topic Docs

Create three new standalone docs:
- `docs/standards/tanstack-query.mdx` — complete Query patterns guide
- `docs/standards/testing-strategy.mdx` — pyramid + MSW + integration patterns
- `docs/standards/solid-principles.mdx` — SOLID applied to NestJS + React

Cross-reference from existing docs.

**Trade-offs:**
- Pro: Focused, deep docs per topic. Easier to find specific guidance.
- Pro: Won't bloat existing docs.
- Con: Agents currently load 3 standards files (referenced in CLAUDE.md Rule 9). Adding 3 new files means agents must discover and load 6 files — double the surface. CLAUDE.md references would need updating.
- Con: Duplication risk — mocking strategies already in `testing.mdx`, DI patterns already in `backend-patterns.mdx`.

**Rough scope:** L (3 new docs at 200-300 lines each, plus cross-references in existing docs)

### Shape 3: Hybrid — TanStack Standalone + Rest Inline

TanStack Query deserves a standalone guide (largest gap, most code examples). SOLID and Testing additions are smaller and fit naturally in existing docs.

- New: `docs/standards/tanstack-query.mdx` (~250 lines) — complete Query patterns
- Extend: `backend-patterns.mdx` += SOLID section (~100 lines)
- Extend: `frontend-patterns.mdx` += SOLID section (~80 lines) + link to TanStack doc
- Extend: `testing.mdx` += MSW section + pyramid rationale (~150 lines)

**Trade-offs:**
- Pro: TanStack gets the depth it needs. Other additions stay proportional.
- Pro: Best balance of focus vs cohesion.
- Con: Mixed strategy — some new files, some extensions.

**Rough scope:** M

## Fit Check

| Requirement | Shape 1 | Shape 2 | Shape 3 |
|-------------|---------|---------|---------|
| Extend existing docs (frame constraint) | Yes | No — 3 new files | Partial — 1 new + 2 extended |
| 1-week appetite | Yes (M) | Borderline (L) | Yes (M) |
| Agent discoverability | No change — 3 files | 6 files (+3 discovery targets) | 4 files (+1 discovery target) |
| No duplication | Yes — single source per domain | Risk — overlaps with existing docs | Low risk — only TanStack standalone |
| Consistent style | Inherits existing format | Must establish new format | Mixed |

**Shape 1 (Extend Existing)** is the best fit:

1. Frame constraint ("extend existing docs") directly favors this approach
2. AI agents already read `frontend-patterns.mdx`, `backend-patterns.mdx`, `testing.mdx` per CLAUDE.md Rule 9 — no new discovery needed
3. Existing docs are ~350 lines; growing to ~500-550 lines is manageable (note: `frontend-patterns.mdx` with TanStack Query may reach ~560 lines — the largest section)
4. Consistent style already established (hierarchical numbering, code examples, AI Quick Reference)

Shape 2 eliminated by the "extend existing docs" constraint and L scope exceeding appetite. Shape 3 is viable but adds a discovery target for a TanStack section that can live in `frontend-patterns.mdx` with a clear heading.

**Recommended: Shape 1** — extend the three existing docs with focused new sections.

## Conclusions

1. **TanStack Query is the highest-priority gap** — large severity, zero existing patterns for agents to follow. Infrastructure (`setupRouterSsrQueryIntegration`, `beforeLoad` pattern) already exists but is unused for data prefetching.
2. **Testing gap is narrower than initially assumed** — `testing.mdx` already documents Testing Trophy, TDD, and mocking strategies. The real gaps are MSW adoption and TanStack Query testing patterns.
3. **SOLID is documentation of existing strengths** — the codebase already follows SOLID implicitly. The work is making it explicit so agents can name the principles they are applying.
4. **Shape 1 (extend existing docs) is the clear winner** — respects frame constraints, avoids fragmentation, and requires no agent discovery changes.

## Next Steps

1. Promote to spec (`/spec --issue 316`) — define exact sections, code examples, and acceptance criteria per sub-issue
2. Spec should address: section ordering within each doc, code example selection, AI Quick Reference additions
3. Implementation: doc-writer agents can work on all 3 docs in parallel since the extensions are independent
