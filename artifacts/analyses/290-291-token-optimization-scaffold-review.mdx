---
title: "Token Optimization — Shared Context Injection & Security-Auditor Scoping"
description: Combined analysis for #290 (scaffold context injection) and #291 (security-auditor scoping) — shapes, cost/benefit, and implementation approaches.
---

**Status:** Draft — 2026-02-24
**Issues:** #290, #291 (children of #251 AI Workflow Improvement Strategy)
**Parent analysis:** [artifacts/analyses/280-token-consumption.mdx](280-token-consumption.mdx)
**Tier:** F-full (user override)

## Context

The [token consumption investigation](280-token-consumption.mdx) identified five hotspots consuming 307k-439k tokens per F-full pipeline run. Token estimates in that document use tool-call-count estimation cross-referenced with session transcript analysis (see [methodology](280-token-consumption.mdx#estimation-methodology)). Two pairs of hotspots are addressable through skill-file changes:

- **Hotspots 3+5** (#290): Scaffold agents independently read the same standards docs and reference patterns. 4-6 agents each read 1-2 of the same files, wasting 8,000-24,000 tokens per scaffold.
- **Hotspots 1+2** (#291): Security-auditor scans 40-100 files per audit instead of targeting changed files. At 18,000-48,000 input tokens per spawn, it's the single most expensive agent.

### Assumptions

These estimates rest on the following assumptions (inherited from the parent analysis unless noted):

| Assumption | Value | Source |
|-----------|-------|--------|
| Chars per token (English + code MDX) | ~4 | Parent analysis; typical range 3.8-4.2 |
| Agents per F-full scaffold | 5 (FE, BE, tester, devops, architect) | Scaffold SKILL.md Step 2c |
| Tokens per file read (security-auditor) | ~500-1,000 | Parent analysis; varies by file size |
| Output tokens cost ~3x input tokens | Yes | Claude API pricing |
| Typical PR size | 8-12 changed files | Parent analysis baseline |

### Current Standards Doc Sizes

| Document | Bytes | Est. Tokens | Read By |
|----------|-------|-------------|---------|
| `frontend-patterns.mdx` | 13,397 | ~3,350 | frontend-dev, tester |
| `backend-patterns.mdx` | 13,728 | ~3,430 | backend-dev, tester |
| `testing.mdx` | 13,062 | ~3,270 | tester, all domain agents |
| `code-review.mdx` | 7,950 | ~1,990 | all review agents |
| **Total** | **48,137** | **~12,040** | |

---

## Part 1: #290 — Shared Context Injection for Scaffold Agents

### Questions Explored

1. What is the most cost-effective way to eliminate redundant standards doc reads across scaffold agents?
2. Where should pre-computed context live — in SKILL.md, in separate files, or generated dynamically?
3. What is the net token savings after accounting for the cost of injecting context (including output token cost)?

### Current Token Flow

During Step 5 (Implement), each scaffold agent is spawned via `Task` with a prompt describing its work. Each agent then independently:

1. Reads CLAUDE.md (~2,000 tokens — agent memory: project)
2. Reads its domain standards doc (~3,300 tokens per doc)
3. Reads testing.mdx if it runs tests (~3,270 tokens)
4. Reads reference feature files to understand patterns (~1,000-3,000 tokens)
5. Reads shared type definitions (~500-1,500 tokens)

For a typical F-full scaffold with 5 agents:

| Agent | Standards Reads | Est. Tokens on Standards |
|-------|----------------|------------------------|
| frontend-dev | frontend-patterns + testing | ~6,620 |
| backend-dev | backend-patterns + testing | ~6,700 |
| tester | testing + (both patterns) | ~9,970 |
| devops | (none specific) | ~0 |
| architect | (reads all for cross-cutting) | ~12,040 |
| **Total** | | **~35,330** |

Of these, `testing.mdx` is read by 3 agents (~9,810 tokens redundant for 2 of them). Both pattern docs are read by the tester and architect in addition to the domain agent. **Estimated redundant reads: ~16,000-22,000 tokens per F-full scaffold.**

### Shape A: Static Curated Excerpts (Pre-built Reference Files)

**Description:** Create per-domain context files in `.claude/skills/scaffold/references/` containing curated excerpts from standards docs. Scaffold SKILL.md Step 5 instructs the orchestrator to read the relevant context file and include it in each agent's Task prompt.

Files created:
- `references/context-frontend.md` — key patterns from frontend-patterns.mdx (~800 tokens)
- `references/context-backend.md` — key patterns from backend-patterns.mdx (~800 tokens)
- `references/context-testing.md` — key patterns from testing.mdx (~800 tokens)
- `references/context-shared.md` — shared conventions (naming, imports, biome) (~400 tokens)

**How it works:**
1. Scaffold Step 2 determines which agents to spawn
2. Step 5 reads the relevant `context-{domain}.md` file(s)
3. Appends the content to each agent's Task prompt
4. Agents receive domain knowledge pre-loaded, skip reading full standards docs

**Token cost (planning):** ~2,400 input tokens to read context files during Step 5 (orchestrator reads 2-3 files)
**Token savings (per agent):** Each agent skips reading 1-2 full standards docs = ~3,300-6,700 tokens saved per agent
**Net savings (5 agents):** ~16,000-22,000 saved - ~2,400 planning cost = **~13,600-19,600 tokens net**

**Risk:** Excerpts diverge from source docs over time. An outdated excerpt silently gives agents stale guidance.
**Maintenance cost:** Must update 4 reference files whenever standards docs change.
**Implementation effort:** Create 4 reference files + modify scaffold SKILL.md Step 5. ~2-3 hours.

### Shape B: Dynamic Read-and-Extract

**Description:** Scaffold Step 2 (Plan) reads the full standards docs relevant to the feature's domains, extracts key sections, and builds a context summary. The summary is injected into each agent's Task prompt in Step 5.

**How it works:**
1. Scaffold Step 2 determines domains involved (FE, BE, testing)
2. Reads full standards docs for those domains (~6,600-12,040 input tokens)
3. Produces extracted summary per domain (~1,500-2,500 output tokens)
4. Writes summary to `artifacts/plans/{issue}-context.md` in the worktree (prevents context-window eviction between Steps 2 and 5)
5. Step 5 reads `artifacts/plans/{issue}-context.md` and injects relevant sections into each agent's prompt

**Token cost (planning):**
- Input: ~6,600-12,040 tokens (reading docs)
- Output: ~1,500-2,500 tokens (extracting) — **output tokens cost ~3x input**, so effective cost = ~4,500-7,500 input-equivalent tokens
- Total effective cost: **~11,100-19,540 input-equivalent tokens**

**Token savings (per agent):** Same as Shape A — agents skip reading full docs = ~3,300-6,700 per agent
**Net savings (5 agents):** ~16,000-22,000 saved - ~11,100-19,540 extraction cost = **~460-10,900 tokens net**

**Risk:**
- Extraction quality depends on the orchestrator deciding which patterns are "key." A hallucinated or omitted pattern in the summary could silently degrade agent output quality.
- On small scaffolds (2-3 agents, Tier F-lite), the extraction cost may exceed savings — net negative.
- Summary format must be templated to avoid wildly varying sizes across runs.

**Maintenance cost:** Zero — always reads current docs.
**Implementation effort:** Modify scaffold SKILL.md Step 2 + Step 5 + define summary template. ~2-3 hours.

### Shape C: Targeted Read Instructions

**Description:** Instead of injecting content, inject *instructions* into each agent's Task prompt telling them exactly which file and section to read. Agents still read the docs but skip the search/discovery phase.

**How it works:**
1. Scaffold Step 5 includes per-agent instructions: "Read `docs/standards/frontend-patterns.mdx` sections: Component Patterns, Hook Rules, Import Conventions"
2. Agents read targeted sections instead of full files + discovery

**Token cost (planning):** ~200 tokens (adding instructions to prompts)
**Token savings (per agent):** Agents read targeted sections vs full files = ~1,000-3,000 per agent (partial reduction — agents still read the file, just skip discovery overhead)
**Net savings (5 agents):** ~5,000-15,000 - ~200 = **~4,800-14,800 tokens net**

**Risk:** Section headers may change when standards docs are edited. Instructions referencing non-existent sections would cause agents to fall back to full reads, negating savings.
**Maintenance cost:** Low — reference section headers rather than line numbers.
**Implementation effort:** Modify scaffold SKILL.md Step 5 only. ~1 hour.

### #290 Fit Check

Requirements:
- **Positive net savings** — must save tokens on a typical F-full scaffold (5 agents)
- **Zero maintenance** — no ongoing upkeep when standards docs evolve
- **Simple implementation** — skill-file changes only, no new tooling
- **Correctness** — agents receive accurate, current information
- **No new artifacts** — avoid files that must be kept in sync

| Requirement | Shape A: Static Excerpts | Shape B: Dynamic Extract | Shape C: Targeted Instructions |
|-------------|--------------------------|-------------------------|-------------------------------|
| Positive net savings | ✅ (13.6k-19.6k) | ⚠️ (0.5k-10.9k, may go negative on small scaffolds) | ✅ (4.8k-14.8k) |
| Zero maintenance | ❌ (excerpt staleness) | ✅ | ✅ |
| Simple implementation | ✅ (new files + SKILL edit) | ⚠️ (needs summary template + temp file) | ✅ (SKILL edit only) |
| Correctness | ❌ (excerpts may lag) | ⚠️ (extraction quality varies) | ✅ (reads source directly) |
| No new artifacts | ❌ (4 new files) | ⚠️ (1 temp file per scaffold) | ✅ |

**Selected shape: Shape C — Targeted Read Instructions.** Simplest implementation, guaranteed correctness (agents read source docs), zero maintenance, and reliably positive net savings. Shape A has the highest savings ceiling but fails on maintenance and correctness. Shape B's output token cost and extraction quality risk narrow its net savings to a range that can go negative, making it unreliable. Shape C's lower ceiling (~14.8k) is acceptable given the zero-risk profile.

**Fallback:** If Shape C's savings prove insufficient after 3 features, escalate to Shape A (accept maintenance cost for higher savings).

---

## Part 2: #291 — Security-Auditor Scoping

### Questions Explored

4. How much scope reduction is achievable for security-auditor without missing vulnerabilities?
5. What is the simplest import resolution approach that captures meaningful dependencies?
6. What is the maintenance burden?

### Current Token Flow

During review Phase 2, the security-auditor is spawned with:
- The full PR diff
- The list of changed files
- Instructions to audit against OWASP Top 10

The auditor then scans broadly:
1. Reads all changed files in full (~500-1,000 tokens per file)
2. Follows imports to read dependencies (1-3 hops deep)
3. Reads adjacent files in the same directories
4. Reads auth-related modules regardless of changes
5. Checks configuration files for misconfigurations

For a typical PR touching 8-12 files, the auditor reads 40-100 files because it explores 2-3 hops of dependencies from each changed file plus entire directory listings.

**Scoping to changed files + 1-hop imports would reduce reads to 15-25 files**, saving 15-75 file reads.

The savings range depends on PR size:
- Small PR (3-5 changed files): auditor reads ~40 files unscoped → ~12 scoped = 28 fewer reads = **~14,000-28,000 tokens saved**
- Medium PR (8-12 files): auditor reads ~60 files → ~20 scoped = 40 fewer reads = **~20,000-40,000 tokens saved**
- Large PR (15+ files): auditor reads ~80-100 files → ~25-35 scoped = 45-65 fewer reads = **~22,500-65,000 tokens saved**

### Alias Resolution Landscape

The codebase uses these import patterns:

| Pattern | Where | Resolution |
|---------|-------|-----------|
| Relative imports (`./foo`, `../bar`) | Everywhere | Resolve relative to importing file's directory |
| `@repo/types` | API + Web | → `packages/types/src/index.ts` (barrel re-export of ~12 sub-files) |
| `@repo/ui` | Web | → `packages/ui/src/` |
| `@repo/config` | API + Web | → `packages/config/src/` |
| `@repo/email` | API | → `packages/email/src/` |
| `@/` | Web only | → `apps/web/src/` (defined in `apps/web/tsconfig.json`) |
| No `@/` alias | API | Uses relative imports and `@repo/*` only |

**Key concern:** `@repo/types` is a barrel file. A 1-hop grep resolves to the barrel entry point (`packages/types/src/index.ts`) but not the individual type files (`rbac.ts`, `auth.ts`, etc.) where actual definitions live. For security analysis, the barrel entry point is sufficient — type definitions rarely contain vulnerabilities. The risk is low.

### Actual Auth Module Structure

The always-include list must match the real codebase structure:

```
apps/api/src/auth/
  auth.controller.ts
  auth.guard.ts          ← the guard lives here, not in src/guards/
  auth.service.ts
  auth.module.ts
  auth.instance.ts
  fastify-headers.ts
  types.ts
  decorators/
    optional-auth.ts
    roles.decorator.ts
    session.decorator.ts
    allow-anonymous.ts
    require-org.decorator.ts
    permissions.decorator.ts
  email/
    email.provider.ts
    resend.provider.ts
    email-send.exception.ts
```

There is **no `apps/api/src/guards/` directory**. Guards live in `apps/api/src/auth/`.

### Shape D: Changed Files Only

**Description:** Review skill passes `git diff --name-only` list directly to security-auditor. The auditor only reads and audits files from this list.

**How it works:**
1. Review Phase 2 runs `git diff --name-only staging...HEAD`
2. Passes the file list to security-auditor prompt: "Audit ONLY these files: {list}"
3. Security-auditor reads and audits only listed files

**Token cost:** ~100 extra tokens in the prompt (file list)
**Net savings:** **~14,000-65,000 tokens** depending on PR size (highest ceiling because most aggressive scoping)

**Risk:** **High.** Misses vulnerabilities in unchanged dependencies. If a changed file calls an auth helper that has a bug, the auditor won't see the helper. Security coverage gaps are unacceptable for a security audit tool — the whole point is catching issues humans miss.

**Implementation effort:** Modify review SKILL.md Phase 2. ~30 minutes.

### Shape E: Changed Files + Grep-Based 1-Hop Imports

**Description:** Review skill gets changed files, greps each for import statements, resolves 1 hop of imports to file paths, and passes the combined list (changed + direct imports + always-include auth modules) to the security-auditor.

**How it works:**
1. Review Phase 2 gets changed files via `git diff --name-only`
2. For each changed file, greps for `import ... from '...'` and `require('...')` statements
3. Resolves imports to file paths using these rules:
   - Relative imports (`./foo`, `../bar`): resolve relative to importing file's directory
   - `@repo/*` packages: map to `packages/{name}/src/index.ts` using hardcoded table: `@repo/types` → `packages/types/src/`, `@repo/ui` → `packages/ui/src/`, `@repo/config` → `packages/config/src/`, `@repo/email` → `packages/email/src/`
   - `@/*` imports (web only): substitute `apps/web/src/`
   - External packages (e.g., `better-auth`, `drizzle-orm`): skip — not local files
4. Adds always-include paths: `apps/api/src/auth/**` (covers guards, decorators, services)
5. Deduplicates and passes combined list to security-auditor

**Token cost:** ~500-1,000 tokens in the prompt (expanded file list + import resolution instructions in SKILL.md)
**Net savings:** **~5,000-35,000 tokens** (reduces to 15-25 file reads from 40-100)

**Risk:**
- Grep-based resolution may miss dynamic imports, re-exports beyond the barrel, or computed imports. Catches ~80-90% of direct dependencies.
- Auth modules are always included as a structural safety net, covering the most security-critical code regardless of import resolution accuracy.
- The security-auditor retains access to Glob/Grep tools and *can* expand scope if a finding warrants investigation — but this is behavioral (prompt-dependent), not structural. The spec should add an explicit instruction: "If a finding requires examining files outside the provided scope, you may expand your read list."

**Maintenance cost:** Low. The `@repo/*` mapping table needs updating if new workspace packages are added (infrequent — last package added was `@repo/email`). Auth path is structural (`apps/api/src/auth/`), unlikely to move.

**Implementation effort:** Modify review SKILL.md Phase 2 with grep commands + alias mapping + always-include list. ~2-3 hours.

### Shape F: Changed Files + Pattern-Based Smart Include

**Description:** Like Shape E but replaces hardcoded auth paths with pattern matching. Auto-detects security-relevant files by scanning for decorators (`@UseGuards`, `@Auth`), middleware patterns, and validation schemas.

**How it works:**
1. Same as Shape E steps 1-3 (changed files + import resolution)
2. Instead of hardcoded always-include paths, runs grep for security patterns:
   - `@UseGuards|@Auth|@Public` → auth guard files
   - `middleware|interceptor` in filenames → middleware files
   - `validation|schema|dto` in filenames → validation files
3. Combines all lists and passes to security-auditor

**Token cost:** ~800-1,500 tokens (more complex instructions + pattern list)
**Net savings:** **~3,500-33,500 tokens** (same file reduction as E, higher instruction overhead)

**Risk:** Pattern matching may over-include (finding pattern-named files that aren't security-relevant) or under-include (missing unconventional security code). In practice, produces the same security coverage as Shape E for this codebase since auth patterns follow NestJS conventions.

**Maintenance cost:** Medium. Pattern list needs updating if security conventions change. More fragile than a stable directory path.

**Implementation effort:** Modify review SKILL.md Phase 2 + possibly security-auditor.md. ~3-4 hours.

### #291 Fit Check

Requirements:
- **Meaningful savings** — must save &gt;5,000 tokens on a typical review
- **Security coverage** — must not miss vulnerabilities in direct dependencies of changed files or in auth modules
- **Simple implementation** — achievable in review SKILL.md without new tooling
- **Low maintenance** — minimal ongoing updates as codebase evolves

| Requirement | Shape D: Changed Only | Shape E: Grep 1-Hop | Shape F: Pattern Smart |
|-------------|----------------------|---------------------|----------------------|
| Meaningful savings | ✅ (14k-65k) | ✅ (5k-35k) | ✅ (3.5k-33.5k) |
| Security coverage | ❌ (misses deps) | ✅ (1-hop + auth always) | ✅ (1-hop + pattern detect) |
| Simple implementation | ✅ | ✅ | ❌ (complex patterns) |
| Low maintenance | ✅ | ✅ (stable alias table + auth path) | ❌ (pattern list evolution) |

**Selected shape: Shape E — Grep-Based 1-Hop Imports.** Best security coverage with manageable complexity. The alias mapping table (`@repo/*` → `packages/*/src/`) is small and stable. The always-include path (`apps/api/src/auth/**`) covers guards, decorators, and services in one glob. Shape D trades too much security coverage for simplicity. Shape F adds complexity without proportional benefit.

---

## Combined Assessment

### Token Savings Estimate

| Optimization | Net Savings (per run) | Derivation | Where |
|-------------|----------------------|------------|-------|
| #290 Shape C (targeted instructions) | 4,800-14,800 tokens | 5 agents × (1k-3k saved) - 200 prompt overhead | Per F-full scaffold |
| #291 Shape E (grep-based scoping) | 5,000-35,000 tokens | (40-100 reads - 15-25 reads) × 500-1k tokens/read - 500-1k prompt overhead | Per review |
| **Combined** | **9,800-49,800 tokens** | 4,800 + 5,000 = 9,800 (floor); 14,800 + 35,000 = 49,800 (ceiling) | **Per F-full pipeline** |

Against the baseline of 307k-439k tokens per F-full pipeline, this represents a **2.2-16.2% reduction**.

**Realistic midpoint:** Small PRs with few agents see ~15k savings; large PRs with full agent teams see ~35k. The floor (9.8k) requires a minimal scaffold + small PR; the ceiling (49.8k) requires a full F-full scaffold + large PR. **Typical run: ~20k-25k savings (~5-7%).**

**Note on compounding:** Both changes increase per-agent prompt size slightly (Shape C adds ~40 tokens of instructions per agent; Shape E adds ~500-1k tokens of file list to security-auditor). This is already accounted for in the overhead deductions above. The changes do not interact — they target different skills (scaffold vs review) that run in different pipeline stages.

### Implementation Approach

Both changes are skill-file-only modifications:

1. **#290:** Add per-domain read instructions to scaffold SKILL.md Step 5. The orchestrator includes targeted section references in each agent's Task prompt (e.g., "Read `frontend-patterns.mdx` sections: Component Patterns, Hook Rules").

2. **#291:** Add file scoping logic to review SKILL.md Phase 2. Before spawning the security-auditor, the orchestrator:
   - Runs `git diff --name-only` to get changed files
   - Greps each for import statements
   - Resolves imports using a hardcoded alias mapping table
   - Adds `apps/api/src/auth/**` as always-include
   - Passes the scoped list to the security-auditor with an explicit "expand if needed" instruction

### Risk Assessment

**#290 (Low risk):**
- Worst case: agents still read full docs despite instructions, negating savings. Net cost: ~200 tokens (the instruction overhead).
- Mitigated by: skipping injection for Tier S scaffolds (no agents to optimize).

**#291 (Medium risk):**
- Worst case: grep misses a critical import, and the auth always-include doesn't cover it. A vulnerability goes undetected.
- Mitigated by: (a) auth modules always included, (b) security-auditor retains Glob/Grep tools to expand scope, (c) explicit SKILL.md instruction to expand if warranted.
- **Behavioral assumption:** The security-auditor expanding scope is prompt-dependent, not guaranteed. The spec should formalize this with a directive in the agent's system prompt or the review SKILL.md.

### Success Criteria

| Criterion | Measurement | Threshold |
|-----------|-------------|-----------|
| #290 net savings positive | Count agent file-read tool calls per scaffold (before vs after) | Fewer total Read calls across all agents vs pre-change baseline |
| #291 net savings positive | Count security-auditor file-read tool calls per review (before vs after) | Reads decrease from 40-100 to 15-30 range |
| #291 no coverage regression | Post-merge vulnerability reports that involved a direct import of a changed file | Zero incidents where the scoped audit would have missed a finding caught by the prior broad scan |
| Combined token reduction | Estimate via tool-call counting (same method as parent analysis) after 3 features | Net savings &gt; 5,000 tokens per pipeline run |

**Rollback signal:** If after 3 features, either (a) net savings &lt; 5,000 tokens per run, or (b) a security finding is missed due to scoping, revert the relevant change.

## Next Steps

- Promote to combined spec for #290 + #291
- Spec should define exact SKILL.md modifications: targeted read instructions (#290), grep commands + alias table + always-include list (#291)
- Spec should include the "expand if needed" directive for security-auditor
- Spec should define the per-domain section references for Shape C (which sections of each standards doc to target)
